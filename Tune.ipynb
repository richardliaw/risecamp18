{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helper import load_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to start off by creating a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def make_model(args):\n",
    "    num_classes = 10\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(args.kernel1, args.kernel1),\n",
    "                     activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(64, (args.kernel2, args.kernel2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(args.poolsize, args.poolsize)))\n",
    "    model.add(Dropout(args.dropout1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(args.hidden, activation='relu'))\n",
    "    model.add(Dropout(args.dropout2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(\n",
    "                      lr=args.lr, momentum=args.momentum),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_mnist(args):\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "    model = make_model(args)\n",
    "    model.fit(x_train, y_train,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Then*, we want to train this model (try out default hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try running a simple search to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Keras MNIST Example')\n",
    "parser.add_argument('--steps', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--kernel1', type=int, default=3,\n",
    "                    help='Size of first kernel (default: 3)')\n",
    "parser.add_argument('--kernel2', type=int, default=3,\n",
    "                    help='Size of second kernel (default: 3)')\n",
    "parser.add_argument('--poolsize', type=int, default=2,\n",
    "                    help='Size of Pooling (default: 2)')\n",
    "parser.add_argument('--dropout1', type=float, default=0.25,\n",
    "                    help='Size of first kernel (default: 0.25)')\n",
    "parser.add_argument('--hidden', type=int, default=128,\n",
    "                    help='Size of Hidden Layer (default: 128)')\n",
    "parser.add_argument('--dropout2', type=float, default=0.5,\n",
    "                    help='Size of first kernel (default: 0.5)')\n",
    "\n",
    "args = parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "14720/60000 [======>.......................] - ETA: 1:07 - loss: 1.5203 - acc: 0.5088"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-09ca4e0ee648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-435b83872813>\u001b[0m in \u001b[0;36mtrain_mnist\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     29\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m               validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 908\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    909\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1143\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1324\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1325\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1328\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1315\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1421\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_mnist(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use this machine with CPUs and multiplex our training to find the best parameters using a single machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from helper import TuneCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist_tune(args, config, reporter):\n",
    "    vars(args).update(config) #add this\n",
    "    x_train, x_test, y_train, y_test = load_data(limit_threads=4) #add this\n",
    "    model = make_model(args)\n",
    "    model.fit(x_train, y_train,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[TuneCallback(reporter)]) #add this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling ray.init() again after it has already been called.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "\n",
      "\n",
      "Created LogSyncer for /Users/rliaw/ray_results/experiment_name/train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057_2018-09-27_20-25-09swpljiao -> \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\tRUNNING\n",
      "\n",
      "Result for train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\n",
      "  date: 2018-09-27_20-25-14\n",
      "  done: false\n",
      "  experiment_id: 971d502824fc41819c007254d48b6206\n",
      "  hostname: C02TX1VXHTDD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.4375\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 33371\n",
      "  time_since_restore: 2.0018250942230225\n",
      "  time_this_iter_s: 2.0018250942230225\n",
      "  time_total_s: 2.0018250942230225\n",
      "  timestamp: 1538105114\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\tRUNNING [pid=33371], 3 s, 2 iter, 0.719 acc\n",
      "\n",
      "Result for train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\n",
      "  date: 2018-09-27_20-25-19\n",
      "  done: false\n",
      "  experiment_id: 971d502824fc41819c007254d48b6206\n",
      "  hostname: C02TX1VXHTDD\n",
      "  iterations_since_restore: 6\n",
      "  mean_accuracy: 0.71875\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 33371\n",
      "  time_since_restore: 7.016580104827881\n",
      "  time_this_iter_s: 1.0017809867858887\n",
      "  time_total_s: 7.016580104827881\n",
      "  timestamp: 1538105119\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\tRUNNING [pid=33371], 8 s, 7 iter, 0.938 acc\n",
      "\n",
      "Result for train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\n",
      "  date: 2018-09-27_20-25-24\n",
      "  done: false\n",
      "  experiment_id: 971d502824fc41819c007254d48b6206\n",
      "  hostname: C02TX1VXHTDD\n",
      "  iterations_since_restore: 11\n",
      "  mean_accuracy: 0.96875\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 33371\n",
      "  time_since_restore: 12.02363133430481\n",
      "  time_this_iter_s: 1.0005419254302979\n",
      "  time_total_s: 12.02363133430481\n",
      "  timestamp: 1538105124\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\tRUNNING [pid=33371], 13 s, 12 iter, 0.812 acc\n",
      "\n",
      "Result for train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\n",
      "  date: 2018-09-27_20-25-29\n",
      "  done: false\n",
      "  experiment_id: 971d502824fc41819c007254d48b6206\n",
      "  hostname: C02TX1VXHTDD\n",
      "  iterations_since_restore: 16\n",
      "  mean_accuracy: 0.90625\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 33371\n",
      "  time_since_restore: 17.032000064849854\n",
      "  time_this_iter_s: 1.00236177444458\n",
      "  time_total_s: 17.032000064849854\n",
      "  timestamp: 1538105129\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 16\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\tRUNNING [pid=33371], 18 s, 17 iter, 0.906 acc\n",
      "\n",
      "Result for train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\n",
      "  date: 2018-09-27_20-25-34\n",
      "  done: false\n",
      "  experiment_id: 971d502824fc41819c007254d48b6206\n",
      "  hostname: C02TX1VXHTDD\n",
      "  iterations_since_restore: 21\n",
      "  mean_accuracy: 0.875\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 33371\n",
      "  time_since_restore: 22.037007808685303\n",
      "  time_this_iter_s: 1.0008950233459473\n",
      "  time_total_s: 22.037007808685303\n",
      "  timestamp: 1538105134\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 21\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\tRUNNING [pid=33371], 23 s, 22 iter, 0.969 acc\n",
      "\n",
      "Result for train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\n",
      "  date: 2018-09-27_20-25-39\n",
      "  done: false\n",
      "  experiment_id: 971d502824fc41819c007254d48b6206\n",
      "  hostname: C02TX1VXHTDD\n",
      "  iterations_since_restore: 26\n",
      "  mean_accuracy: 0.9375\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 33371\n",
      "  time_since_restore: 27.0503191947937\n",
      "  time_this_iter_s: 1.004991054534912\n",
      "  time_total_s: 27.0503191947937\n",
      "  timestamp: 1538105139\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 26\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\tRUNNING [pid=33371], 28 s, 27 iter, 0.906 acc\n",
      "\n",
      "Result for train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\n",
      "  date: 2018-09-27_20-25-43\n",
      "  done: true\n",
      "  experiment_id: 971d502824fc41819c007254d48b6206\n",
      "  hostname: C02TX1VXHTDD\n",
      "  iterations_since_restore: 30\n",
      "  mean_accuracy: 1.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 33371\n",
      "  time_since_restore: 31.056740522384644\n",
      "  time_this_iter_s: 1.0015830993652344\n",
      "  time_total_s: 31.056740522384644\n",
      "  timestamp: 1538105143\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 30\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057:\tTERMINATED [pid=33371], 31 s, 30 iter, 1 acc\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[train_mnist_0_dropout1=0.68217,hidden=297,lr=0.073576,momentum=0.69057]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)\n",
    "tune.register_trainable(\n",
    "    \"train_mnist\", lambda config, reporter: train_mnist_tune(args, config, reporter))\n",
    "\n",
    "configuration = tune.Experiment(\n",
    "    \"experiment_name\",\n",
    "    stop={\"mean_accuracy\": 0.99},\n",
    "    run=\"train_mnist\",\n",
    "    config={\n",
    "        \"lr\": lambda spec: np.random.uniform(0.001, 0.1),\n",
    "        \"momentum\": lambda spec: np.random.uniform(0.1, 0.9),\n",
    "        \"hidden\": lambda spec: np.random.randint(32, 512),\n",
    "        \"dropout1\": lambda spec: np.random.uniform(0.2, 0.8),\n",
    "    }\n",
    ")\n",
    "tune.run_experiments(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tune.Trainable):\n",
    "    def _setup(self):\n",
    "        vars(args).update(self.config) #add this\n",
    "        self.model = make_model(args)\n",
    "        self.data = load_data(limit_threads=4)\n",
    "    \n",
    "    def _train(self):\n",
    "        x_train, x_test, y_train, y_test = self.data\n",
    "        result = self.model.fit(x_train, y_train,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test)) #add this\n",
    "        return {\"mean_accuracy\": result.history[\"acc\"][0]}\n",
    "    \n",
    "    def _save(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"weights.h5\")\n",
    "        self.model.save_weights(checkpoint_path)\n",
    "    \n",
    "    def _restore(self, checkpoint_path):\n",
    "        self.model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling ray.init() again after it has already been called.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "\n",
      "\n",
      "Created LogSyncer for /Users/rliaw/ray_results/experiment_name/Model_0_dropout1=0.59719,hidden=288,lr=0.044971,momentum=0.33499_2018-09-27_23-00-1552ds5byk -> \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - Model_0_dropout1=0.59719,hidden=288,lr=0.044971,momentum=0.33499:\tRUNNING\n",
      "\n",
      "Remote function \u001b[31mtrain\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rliaw/Research/riselab/ray/python/ray/worker.py\", line 945, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/rliaw/Research/riselab/ray/python/ray/actor.py\", line 261, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/rliaw/Research/riselab/ray/python/ray/tune/trainable.py\", line 143, in train\n",
      "    result = self._train()\n",
      "  File \"<ipython-input-13-d3e5934c35d8>\", line 12, in _train\n",
      "TypeError: 'History' object is not subscriptable\n",
      "\n",
      "Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rliaw/Research/riselab/ray/python/ray/tune/trial_runner.py\", line 239, in _process_events\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/rliaw/Research/riselab/ray/python/ray/tune/ray_trial_executor.py\", line 200, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/Users/rliaw/Research/riselab/ray/python/ray/worker.py\", line 2522, in get\n",
      "    raise RayGetError(object_ids, value)\n",
      "ray.worker.RayGetError: Could not get objectid ObjectID(010000005197786ba2f93493fcaf82af526abcf5). It was created by remote function \u001b[31mtrain\u001b[39m which failed with:\n",
      "\n",
      "Remote function \u001b[31mtrain\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rliaw/Research/riselab/ray/python/ray/worker.py\", line 945, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/rliaw/Research/riselab/ray/python/ray/actor.py\", line 261, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/rliaw/Research/riselab/ray/python/ray/tune/trainable.py\", line 143, in train\n",
      "    result = self._train()\n",
      "  File \"<ipython-input-13-d3e5934c35d8>\", line 12, in _train\n",
      "TypeError: 'History' object is not subscriptable\n",
      "\n",
      "Worker ip unknown, skipping log sync for /Users/rliaw/ray_results/experiment_name/Model_0_dropout1=0.59719,hidden=288,lr=0.044971,momentum=0.33499_2018-09-27_23-00-1552ds5byk\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "ERROR trials:\n",
      " - Model_0_dropout1=0.59719,hidden=288,lr=0.044971,momentum=0.33499:\tERROR, 1 failures: /Users/rliaw/ray_results/experiment_name/Model_0_dropout1=0.59719,hidden=288,lr=0.044971,momentum=0.33499_2018-09-27_23-00-1552ds5byk/error_2018-09-27_23-02-37.txt\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/rliaw/ray_results/experiment_name\n",
      "ERROR trials:\n",
      " - Model_0_dropout1=0.59719,hidden=288,lr=0.044971,momentum=0.33499:\tERROR, 1 failures: /Users/rliaw/ray_results/experiment_name/Model_0_dropout1=0.59719,hidden=288,lr=0.044971,momentum=0.33499_2018-09-27_23-00-1552ds5byk/error_2018-09-27_23-02-37.txt\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [Model_0_dropout1=0.59719,hidden=288,lr=0.044971,momentum=0.33499])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bff8ef80f880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcheckpoint_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Research/riselab/ray/python/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, search_alg, scheduler, with_server, server_port, verbose, queue_trials, trial_executor)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mwait_for_log_sync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [Model_0_dropout1=0.59719,hidden=288,lr=0.044971,momentum=0.33499])"
     ]
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)\n",
    "configuration = tune.Experiment(\n",
    "    \"experiment_name\",\n",
    "    stop={\"mean_accuracy\": 0.99},\n",
    "    run=Model,\n",
    "    config={\n",
    "        \"lr\": lambda spec: np.random.uniform(0.001, 0.1),\n",
    "        \"momentum\": lambda spec: np.random.uniform(0.1, 0.9),\n",
    "        \"hidden\": lambda spec: np.random.randint(32, 512),\n",
    "        \"dropout1\": lambda spec: np.random.uniform(0.2, 0.8),\n",
    "    },\n",
    "    checkpoint_at_end=True\n",
    ")\n",
    "tune.run_experiments(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
